{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c93cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Ingestion  ##############################\n",
    "def Site_BOM_data_ingestion(Pathtot_TrainBOM, Path_toFASID, Path_toBOM_Anom_Scoring):\n",
    "\n",
    "    ############################ LOAD ALL LIBRARIES @@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    import csv\n",
    "\n",
    
    "    import glob\n",
    "    import os\n",
    "    import sys\n",
    "    #!pip install numpy>=1.17\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    #global all_ops_bom_anomalyScore_file_df\n",
    "\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    #pd.set_option('max_columns', None)\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install h2o\n",
    "    import seaborn as sns\n",
    "    #import h2o\n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,Normalizer\n",
    "    #from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize']=15,10\n",
    "\n",
    "    import time\n",
    "    !pip install sklearn --use-feature=2020\n",
    "    start = time.time()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from math import log10, floor\n",
    "    from sklearn import metrics\n",
    "    from statsmodels.distributions.empirical_distribution import ECDF\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    ###############Random Bagging Ensemble- using- Bagging - random sample with replacement, \n",
    "    ## Random sampling using features subsets-Random Sub-Space, & Random sampling- combine both Features \n",
    "    ### & Sample -Random batches ####\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    ########### Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    #import loguniform\n",
    "\n",
    "    ############GBM \n",
    "    #import lightgbm as lgb\n",
    "    ###############\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ####### Cell multiple Display  ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    ####### GridSearch and Skllearn Libraries\n",
    "\n",
    "    #Data Mining\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    #import model_selection \n",
    "    import statsmodels\n",
    "\n",
    "    #Classifier scoring\n",
    "    from sklearn import metrics\n",
    "    import csv\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    ## working directory\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    # ####### Class Imbalance SMOTE ######\n",
    "    !pip install imblearn\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "    #from StringIO import StringIO\n",
    "    import gzip\n",
    "    #from urllib import urlopen\n",
    "\n",
    "    import requests\n",
    "    #from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    ##os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\sipp')\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "\n",
    "    ##  Code Execution time\n",
    "\n",
    "    import matplotlib.pylab as plt\n",
    "    import statsmodels\n",
    "    %matplotlib inline\n",
    "    from matplotlib.pylab import rcParams\n",
    "    rcParams['figure.figsize'] = 15, 6\n",
    "    import numpy as np; np.random.seed(136)\n",
    "\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    from matplotlib import pylab\n",
    "    from matplotlib import style\n",
    "    import seaborn as sns\n",
    "    sns.set_style('whitegrid')\n",
    "    import seaborn as sns; sns.set(color_codes=True)\n",
    "    from matplotlib import style\n",
    "    style.use('ggplot')\n",
    "    mpl.rcParams['lines.linewidth'] = 2\n",
    "    mpl.rcParams['lines.color'] = 'r'\n",
    "    from numpy import argmax\n",
    "    ########## Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    # import loguniform\n",
    "    # from sklearn.datasets import load_digits\n",
    "    # from sklearn.linear_model import SGDClassifier\n",
    "    # ### Warning messages mode  ####\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    ####### Cell multiple Display Config ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    #path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "    path1=os.getcwd()\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "    ############# Printing Plot output ###############\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    pd.options.display.max_rows = 4000\n",
    "    ############################# Decision Tree Plots & Viz Libs  #####################\n",
    "    import scipy\n",
    "    from sys import getsizeof\n",
    "    from IPython.display import Image\n",
    "    from matplotlib import pylab\n",
    "    from sklearn.tree import _tree\n",
    "    #from skrules import SkopeRules\n",
    "    ###### Accuracy Paramters\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "    import unittest\n",
    "    ## range to xrange copatability in python 2 &#3\n",
    "#     try:\n",
    "#         # Python 2 forward compatibility\n",
    "#         range = xrange\n",
    "#     except:\n",
    "#             \"NameError\"\n",
    "#     pass\n",
    "\n",
    "    #####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "    import future  , builtins , past, six      \n",
    "    from six import reraise as raise_\n",
    "    from future.utils import raise_\n",
    "\n",
    "    ###################### Model Pickling & JSON Support Loads #################\n",
    "    import pickle\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    import base64\n",
    "    import string\n",
    "    import re\n",
    "    #############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # import gensim\n",
    "    import os\n",
    "    import collections\n",
    "    # import smart_open\n",
    "    import random\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    ###################### IMPORT MODEL JOBLIB @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "\n",
    "    #from __future__ import print_function\n",
    "\n",
    "    import json\n",
    "\n",
    "    import sys\n",
    "    import traceback\n",
    "    import time\n",
    "    import socket\n",
    "    from collections import Counter\n",
    "\n",
    "    !conda install -c conda-forge h2o-py openjdk -y\n",
    "\n",
    "    #import boto3\n",
    "    from   IPython                   import display\n",
    "    import matplotlib.pyplot         as plt\n",
    "    import numpy                     as np\n",
    "    import pandas                    as pd\n",
    "    # import sagemaker\n",
    "    # from sagemaker.tensorflow import TensorFlow\n",
    "    # from sagemaker.tensorflow.serving import Model, Predictor\n",
    "    # from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "    # from   sklearn.decomposition     import PCA\n",
    "    # #!pip install pytest-astropy    ############# Prequisite for Tensorflow install\n",
    "    !pip install tensorflow\n",
    "    import tensorflow                as tf\n",
    "    from   tensorflow                import keras\n",
    "    from   tensorflow.keras.datasets import mnist\n",
    "    import tensorflow.keras.backend  as K\n",
    "    import time\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from scipy       import stats\n",
    "    from statistics  import mean\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    ######## Comnine ALL Operators BOM for Train/Validate CSVs in One Folder @@@@@@\n",
    "    path1=Pathtot_TrainBOM\n",
    "    all_trainfiles = glob.glob(os.path.join(path1,\"*.csv\"))    # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "    all_ops_bom_train_val_df = pd.concat((pd.read_csv(f, header=0,  sep=',',  encoding=\"utf-8-sig\" , error_bad_lines=False) for f in all_trainfiles), ignore_index=True)\n",
    "    #all_ops_bom_train_val_df = pd.read_csv(path1, header=0,  sep=',',  encoding=\"utf-8\" , error_bad_lines=False, index_col=None)\n",
    "    ##utf-8-sig\n",
    "\n",
    "    \n",
    "    #all_ops_bom_train_val_df   = pd.concat(all_ops_bom_train_val, ignore_index=True), index_col=None,\n",
    "    #quoting=csv.QUOTE_NONE#############,quoting=csv.QUOTE_NO\n",
    "    ########### END of Training/Validation All CSV BOM Files from ALL Operators Site BOMS  Ingestions @@@@@@@@@@@@\n",
    "    ## utf-8-sig \n",
    "    ## ISO-8859-1\n",
    "    ########################## FAS_DI SET INGESTION @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    path2=Path_toFASID\n",
    "    all_FASfiles = glob.glob(os.path.join(path2,\"*.csv\"))    # advisable to use os.path.join as this makes concatenation OS independent\n",
    "    all_FASfiles_df = pd.concat((pd.read_csv(f, header=0,  sep=',',  encoding=\"utf-8-sig\" , error_bad_lines=False) for f in all_FASfiles), ignore_index=True)\n",
    "    \n",
    "    #all_FASfiles_df = pd.read_csv(path2, header=0,  sep=',',  encoding=\"utf-8\" , error_bad_lines=False, index_col=None) \n",
    "    #all_FASfiles_df   = pd.concat(all_ops_bom_FAS, ignore_index=True) index_col=None,\n",
    "    \n",
    "    ######### END of FAS ID Set Ingestion @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    \n",
    "     ######## Comnine ALL Operators Site BOM To Score for Anomaly CSVs in Another Folder @@@@@@\n",
    "     ######### Site BOM Anomaly Detection CSV Folder Will be the Site BOM Anomaly Output Folder @@@@@@@@@@@@\n",
    "    path3=Path_toBOM_Anom_Scoring\n",
    "    all_ops_bom_anomalyScore = glob.glob(os.path.join(path3,\"*.csv\"))    # advisable to use os.path.join as this makes concatenation OS independent\n",
    "    #ISO-8859-1\n",
    "    #all_ops_bom_anomalyScore_file_df = pd.read_csv(path3, header=0,  sep=',',  encoding=\"utf-8\" , error_bad_lines=False, index_col=None)\n",
    "    \n",
    "    all_ops_bom_anomalyScore_file_df = pd.concat((pd.read_csv(f, header=0,  sep=',',  encoding=\"ISO-8859-1\" , error_bad_lines=False, quoting=csv.QUOTE_NONE ) for f in all_ops_bom_anomalyScore),ignore_index=True)\n",
    "    \n",
    "    #all_ops_bom_anomalyScore_file_df   = pd.concat(all_ops_bom_anomalyScore_file, ignore_index=True) index_col=None,\n",
    "        \n",
    "    ##### END of All Operators Site BOM Anomaly Detection CSV  Ingestions @@@@@@@@@@@@\n",
    "    \n",
    "#     all_ops_bom_train_val_df= pd.read_csv(Path_1 , sep=';',  encoding=\"utf-8-sig\" )\n",
    "#     all_ops_bom_train_val_df_w= pd.read_csv(Path_2, sep=',',  encoding=\"utf-8-sig\" )\n",
    "#     bom_a= pd.read_csv(Path_3, sep=',',  encoding=\"utf-8-sig\" )\n",
    "#     all_ops_bom_anomalyScore_file_df= pd.read_csv(Path_4 , sep=',',  encoding=\"ISO-8859-1\" )\n",
    "#     fas_id=pd.read_csv(Path_5, sep=',' ,  encoding=\"ISO-8859-1\" )\n",
    "#     # all_ops_bom_train_val_df.shape\n",
    "#     fas_id.shape\n",
    "#     print(fas_id.head())\n",
    "    # bom_sect17.shape\n",
    "    # bom_sect1.shape\n",
    "\n",
    "    print(all_ops_bom_train_val_df.shape, all_FASfiles_df.shape, all_ops_bom_anomalyScore_file_df.shape ,\\\n",
    "          all_ops_bom_train_val_df.head(),all_FASfiles_df.head() , all_ops_bom_anomalyScore_file_df.head())\n",
    "    #, all_FASfiles_df.shape all_FASfiles_df.head(),\n",
    "    return all_ops_bom_train_val_df, all_ops_bom_anomalyScore_file_df\n",
    "    #  all_FASfiles_df,\n",
    "###################################### MODEL Data Pre-Prep & Feature Engineering   ##################\n",
    "def SiteBOM_Data_Train_preprocess_pipe (all_ops_bom_train_val_df,  all_ops_bom_anomalyScore_file_df):\n",
    "    #global June_july_august_all_df3,  all_FASfiles_df,\n",
    "    \n",
    "    ######################### Declaring Global Variables ######################################\n",
    "    global ESR_approved_bom_11\n",
    "    global ESR_approved_bom_22\n",
    "    global ESR_approved_bom_11_4\n",
    "    global ESR_approved_bom_22_4\n",
    "    global all_ops_bom_anomalyScore_file_df_4_5\n",
    "    #global all_ops_bom_anomalyScore_file_df\n",
    "    global all_ops_bom_anomalyScore_file_df_3\n",
    "   \n",
    "    ########################################### Loading Libararies ###############################3\n",
    "    ############################ LOAD ALL LIBRARIES @@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    import csv\n",
    "    import glob\n",
    "    import os\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    #pd.set_option('max_columns', None)\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install h2o\n",
    "    import seaborn as sns\n",
    "    #import h2o\n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,Normalizer\n",
    "    #from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize']=15,10\n",
    "\n",
    "    import time\n",
    "    !pip install sklearn --use-feature=2020\n",
    "    start = time.time()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from math import log10, floor\n",
    "    from sklearn import metrics\n",
    "    from statsmodels.distributions.empirical_distribution import ECDF\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    ###############Random Bagging Ensemble- using- Bagging - random sample with replacement, \n",
    "    ## Random sampling using features subsets-Random Sub-Space, & Random sampling- combine both Features \n",
    "    ### & Sample -Random batches ####\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    ########### Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    #import loguniform\n",
    "\n",
    "    ############GBM \n",
    "    #import lightgbm as lgb\n",
    "    ###############\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ####### Cell multiple Display  ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    ####### GridSearch and Skllearn Libraries\n",
    "\n",
    "    #Data Mining\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    #import model_selection \n",
    "    import statsmodels\n",
    "\n",
    "    #Classifier scoring\n",
    "    from sklearn import metrics\n",
    "    import csv\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    # ####### Class Imbalance SMOTE ######\n",
    "    !pip install imblearn\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "    #from StringIO import StringIO\n",
    "    import gzip\n",
    "    #from urllib import urlopen\n",
    "\n",
    "    import requests\n",
    "    #from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    ##os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\sipp')\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "\n",
    "    ##  Code Execution time\n",
    "\n",
    "    import matplotlib.pylab as plt\n",
    "    import statsmodels\n",
    "    %matplotlib inline\n",
    "    from matplotlib.pylab import rcParams\n",
    "    rcParams['figure.figsize'] = 15, 6\n",
    "    import numpy as np; np.random.seed(136)\n",
    "\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    from matplotlib import pylab\n",
    "    from matplotlib import style\n",
    "    import seaborn as sns\n",
    "    sns.set_style('whitegrid')\n",
    "    import seaborn as sns; sns.set(color_codes=True)\n",
    "    from matplotlib import style\n",
    "    style.use('ggplot')\n",
    "    mpl.rcParams['lines.linewidth'] = 2\n",
    "    mpl.rcParams['lines.color'] = 'r'\n",
    "    from numpy import argmax\n",
    "    ########## Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    # import loguniform\n",
    "    # from sklearn.datasets import load_digits\n",
    "    # from sklearn.linear_model import SGDClassifier\n",
    "    # ### Warning messages mode  ####\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    ####### Cell multiple Display Config ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    #path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "    path1=os.getcwd()\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "    ############# Printing Plot output ###############\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    pd.options.display.max_rows = 4000\n",
    "    ############################# Decision Tree Plots & Viz Libs  #####################\n",
    "    import scipy\n",
    "    from sys import getsizeof\n",
    "    from IPython.display import Image\n",
    "    from matplotlib import pylab\n",
    "    from sklearn.tree import _tree\n",
    "    #from skrules import SkopeRules\n",
    "    ###### Accuracy Paramters\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "    import unittest\n",
    "    ## range to xrange copatability in python 2 &#3\n",
    "#     try:\n",
    "#     # Python 2 forward compatibility\n",
    "#         range = xrange\n",
    "#     except:\n",
    "#         'NameError'\n",
    "#         pass\n",
    "\n",
    "    #####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "    import future  , builtins , past, six      \n",
    "    from six import reraise as raise_\n",
    "    from future.utils import raise_\n",
    "\n",
    "    ###################### Model Pickling & JSON Support Loads #################\n",
    "    import pickle\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    import base64\n",
    "    import string\n",
    "    import re\n",
    "    #############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # import gensim\n",
    "    import os\n",
    "    import collections\n",
    "    # import smart_open\n",
    "    import random\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    ###################### IMPORT MODEL JOBLIB @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "\n",
    "    #from __future__ import print_function\n",
    "\n",
    "    import json\n",
    "\n",
    "    import traceback\n",
    "    import time\n",
    "    import socket\n",
    "    from collections import Counter\n",
    "\n",
    "    !conda install -c conda-forge h2o-py openjdk -y\n",
    "\n",
    "    #import boto3\n",
    "    from   IPython                   import display\n",
    "    import matplotlib.pyplot         as plt\n",
    "    import numpy                     as np\n",
    "    import pandas                    as pd\n",
    "    # import sagemaker\n",
    "    # from sagemaker.tensorflow import TensorFlow\n",
    "    # from sagemaker.tensorflow.serving import Model, Predictor\n",
    "    # from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "    # from   sklearn.decomposition     import PCA\n",
    "    # #!pip install pytest-astropy    ############# Prequisite for Tensorflow install\n",
    "    !pip install tensorflow\n",
    "    import tensorflow                as tf\n",
    "    from   tensorflow                import keras\n",
    "    from   tensorflow.keras.datasets import mnist\n",
    "    import tensorflow.keras.backend  as K\n",
    "    import time\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from scipy       import stats\n",
    "    from statistics  import mean\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    ### Create Retrun BOM SUBSET for BOM Anomaly Model TEST @@@@@@@@@@@@@@@\n",
    "    all_ops_bom_anomalyScore_file_df_3= all_ops_bom_anomalyScore_file_df[['QuantityAggregatedBom','SourcingProviderAggrBom','MaterialCategoryAggrBom','DiscriminatorAggrBom','ProductNumber','ProductDescription']]\n",
    "        \n",
    "    #all_ops_bom_anomalyScore_file_df_3= all_ops_bom_anomalyScore_file_df[['Deliverable Name','Link to Deliverable','FP_SiteType','Commodity','Quantity','Ericsson Product Number', 'Ericsson Product Description','Material Category', 'Sourcing Provider']]\n",
    "    ### 'Deliverable Name', add as needed\n",
    "    all_ops_bom_anomalyScore_file_df_3.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.head())\n",
    "    \n",
    "    #### JOIN ALL the THREE OPERATORS APPROVED BOM SET FOR AUTOENCODER MODEL For BOM ANOMALY DETECTION TRAINING @@@ \n",
    "    #all_ops_bom_train_val_df.drop('DeliverableId(AggregatedBom)', axis=1, inplace=True) \n",
    "    #all_ops_bom_train_val_df.rename(columns={'DeliverableId(AggregatedBom)': 'DeliverableId'}, inplace=True)\n",
    "    ## DeliverableId\n",
    "    print(all_ops_bom_train_val_df.columns)\n",
    "    #all_ops_bom_train_val_df_w.rename(columns={'DeliverableId(AggregatedBom)': 'DeliverableId'}, inplace=True)\n",
    "    #all_ops_bom_train_val_df_w.columns\n",
    "    #print(all_ops_bom_train_val_df_w.head())\n",
    "    all_ops_bom_train_val_df.to_csv('all_ops_bom_train_val_df.csv')      \n",
    "    print(all_ops_bom_train_val_df.shape, all_ops_bom_train_val_df.head())\n",
    "    #print(all_ops_bom_train_val_df['DeliverableId'].nunique(), all_ops_bom_train_val_df['DeliverableId'].nunique(), all_ops_bom_train_val_df['DeliverableId'].nunique())\n",
    "    \n",
    "    ############################ JOIN THE THREE OPERATORS SET @@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    #################################### JOIN ALL THREE @@@@@@@@@@@@@@@@@@@@@\n",
    "    #frames = [all_ops_bom_train_val_df, bom_a, all_ops_bom_train_val_df_w]\n",
    "   # bom_join = pd.concat(frames)\n",
    "    \n",
    "    #bom_join.shape\n",
    "    #print(bom_join.head())\n",
    "    #print(bom_join.isnull().sum(axis=0))\n",
    "    \n",
    "    ### JOIN THE OPERATORS SET with FAS ID Set to Bring in SiteType Dimension to Model Training @@@@@@\n",
    "    ################### First Drop Duplicates for 'DeliverableId' , beofre Merge FAS Set with Trainset @@@@@@@@@@@@@@@@@@@@@\n",
    "#     all_ops_bom_train_val_df.drop_duplicates(subset=['DeliverableId'], inplace=True)\n",
    "#     all_FASfiles_df.drop_duplicates(subset=['DeliverableId'], inplace=True)\n",
    "    \n",
    "    all_ops_bom_train_val_df_2=all_ops_bom_train_val_df.drop_duplicates(subset=['DeliverableId'])\n",
    "    ## 'NoteAggrBom'\n",
    "    #bom_join_6=all_ops_bom_train_val_df.drop_duplicates(subset=['DeliverableId'])\n",
    "    #bom_join_6= all_ops_bom_train_val_df.drop('NoteAggrBom', axis=1)\n",
    "    all_FASfiles_df_2=all_FASfiles_df.drop_duplicates(subset=['DeliverableId'])\n",
    "    \n",
    "    #bom_join_6 =all_ops_bom_train_val_df_2.merge(all_FASfiles_df_2, on=['DeliverableId'] ,how='outer')\n",
    "    bom_join_6 = pd.concat([all_ops_bom_train_val_df_2, all_FASfiles_df_2], ignore_index=True)\n",
    "    #pd.concat([s1, s2], ignore_index=True)\n",
    "    pd.concat\n",
    "    bom_join_6.shape\n",
    "    print(bom_join_6.head())\n",
    "    ############ Save Set @@@@@@@@@@@@@@@@@@\n",
    "    bom_join_6.to_csv('bom_join_6.csv')\n",
    "    \n",
    "    ###################### format date @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@2\n",
    "    bom_join_6['ForecastedConstructionDate'] =pd.to_datetime(bom_join_6['ForecastedConstructionDate'], infer_datetime_format=True, errors='coerce')\n",
    "    bom_join_6['ForecastedConstructionDate'].head()\n",
    "    bom_join_6['ForecastedConstructionDate'].min()\n",
    "    bom_join_6['ForecastedConstructionDate'].max()\n",
    "\n",
    "    bom_join_6['BOMDataLoadTime'] =pd.to_datetime(bom_join_6['BOMDataLoadTime'], infer_datetime_format=True, errors='coerce')\n",
    "     ################### MODEL TARGET- SCENARIO #1  ######################################################################\n",
    "    bom_join_6['BOMDataLoadTime'].min()\n",
    "    bom_join_6['BOMDataLoadTime'].max()\n",
    "    print(bom_join_6['BOMDataLoadTime'].head())\n",
    "\n",
    "    #bom_join_6['DeliverableName(Bom)'].nunique()\n",
    "    #print(bom_join_6['DeliverableName(Bom)'].value_counts())\n",
    "\n",
    "    #all_ops_bom_anomalyScore_file_df.columns\n",
    "    #all_ops_bom_anomalyScore_file_df['Deliverable Name'].nunique()\n",
    "    #print(all_ops_bom_anomalyScore_file_df['Deliverable Name'].value_counts())\n",
    "          \n",
    "    #### CREATE THE TRAIN /VAIDATE 7 FEATURES ONLY SET FROM THE THREE OPERATORS JOINED BOM SET @@@@@@@@\n",
    "          \n",
    "    #bom_join_8= bom_join_6[['SiteType','DiscriminatorAggrBom', 'QuantityAggregatedBom','ProductNumber', 'ProductDescription','MaterialCategoryAggrBom', 'SourcingProviderAggrBom']]\n",
    "    bom_join_8= bom_join_6[['DiscriminatorAggrBom', 'QuantityAggregatedBom','ProductNumber', 'ProductDescription','MaterialCategoryAggrBom', 'SourcingProviderAggrBom']]\n",
    "    #bom_join_8= bom_join_6[['ProductNumber', 'ProductDescription']], 'CommodityAggrBom',\n",
    "    #'DiscriminatorAggrBom', 'QuantityAggregatedBom','ProductNumber', 'ProductDescription','MaterialCategoryAggrBom', 'SourcingProviderAggrBom'\n",
    "    ## 'DeliverableName(Bom)',   addd as needed\n",
    "    bom_join_8.shape\n",
    "    bom_join_8.columns\n",
    "    print(bom_join_8.head())\n",
    "          \n",
    "    ### Rename the BAD ESR BOM columns to Match corresponding Good BOM /Approved  Joined Sets @@@@      \n",
    "    #all_ops_bom_anomalyScore_file_df_3.rename(columns={'Ericsson Product Description': 'ProductDescription', \"Ericsson Product Number\": \"ProductNumber\" }, errors=\"raise\", inplace=True)\n",
    "    \n",
    "    \n",
    "    all_ops_bom_anomalyScore_file_df_3.shape\n",
    "    all_ops_bom_anomalyScore_file_df_3.columns\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.head())\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.isnull().sum())\n",
    "    \n",
    "    #### DROP the EXTRA Features in RETURN BOM SET to Match Good BOM Train Set @@@@@@@@@@@@@\n",
    "    all_ops_bom_anomalyScore_file_df_3.columns\n",
    "    #all_ops_bom_anomalyScore_file_df_3= all_ops_bom_anomalyScore_file_df_3.drop(['DiscriminatorAggrBom','SiteType' ], axis=1)\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.shape, all_ops_bom_anomalyScore_file_df_3.columns, all_ops_bom_anomalyScore_file_df_3.head())\n",
    "    \n",
    "    #### CREATE the 7 Features SET from Three OPERATORS Joined Set for FIANL MODEL Training @@@@@@@@@@@@\n",
    "    bom_join_9=bom_join_6[[ 'QuantityAggregatedBom',\n",
    "       'ProductNumber', 'ProductDescription', 'MaterialCategoryAggrBom',\n",
    "       'SourcingProviderAggrBom', 'DiscriminatorAggrBom']]\n",
    "    ## , 'CommodityAggrBom'\n",
    "    \n",
    "    \n",
    "    print(bom_join_9.shape, bom_join_9.columns, bom_join_9.head())\n",
    "    \n",
    "    #### SPLIT TRAIN & Validate @@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    ESR_approved_bom_11, ESR_approved_bom_22 = train_test_split(bom_join_9, test_size=0.25, random_state=42)\n",
    "#     ESR_approved_bom_11['MaterialCategoryAggrBom'].value_counts()\n",
    "#     ESR_approved_bom_22['MaterialCategoryAggrBom'].value_counts()\n",
    "    print(ESR_approved_bom_11.shape, ESR_approved_bom_22.shape)\n",
    "    print(ESR_approved_bom_11[0:5],  ESR_approved_bom_22[0:5])\n",
    "    \n",
    "    ### Create Validation Set & Save to file to Save to Bucket @@@@@\n",
    "    ESR_approved_bom_22.to_csv(\"ESR_approved_bom_22_AMPVer.csv\")\n",
    "    ESR_approved_bom_11.to_csv('ESR_approved_bom_11_AMPVer.csv')\n",
    "\n",
    "    ### Prepare Train to Create the H2O MODEL For SAGE MAKER MODEL OBJECT to Fullfil Bring YOur Own Model@@@@@@@\n",
    "    ### Will be Used to Deploy BOM Anomaly Detection Model on AMP @@@@@@@@@@@@@@@@@\n",
    "    ESR_approved_bom_11.shape\n",
    "    print(ESR_approved_bom_11.isnull().sum())\n",
    "    print(ESR_approved_bom_11.head())\n",
    "\n",
    "    ESR_approved_bom_11.shape\n",
    "    ###################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    perc = 80.0 # Like N %\n",
    "    min_count =  int(((100-perc)/100)*ESR_approved_bom_11.shape[0] + 1)\n",
    "    ESR_approved_bom_11_3 = ESR_approved_bom_11.dropna( axis=1, thresh=min_count)\n",
    "    # DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    ESR_approved_bom_11_3 .shape\n",
    "    print(ESR_approved_bom_11_3 .head())\n",
    "    ##################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    ####################### IMPUTE With Higest Fresq. Value @@@@@@@@@@@@\n",
    "    ESR_approved_bom_11_4=ESR_approved_bom_11_3.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    ESR_approved_bom_11_4.isnull().sum(axis=0)\n",
    "    ESR_approved_bom_11_4.shape\n",
    "    print(ESR_approved_bom_11_4.head())\n",
    "\n",
    "    \n",
    "    ### Impute & Encode Train SET of Good BOM SET, Validation and Test Return SETS @@@@@@@@@@\n",
    "    ### Impute Train SET of Good BOM SET @@@@@@@@@@@@@@\n",
    "    #ESR_approved_bom_11_4['DeliverableId']=ESR_approved_bom_11_4.astype({'DeliverableId': 'object'}, copy=True).dtypes\n",
    "    ESR_approved_bom_11_4.dtypes\n",
    "    \n",
    "    ESR_approved_bom_11_4.shape\n",
    "    ESR_approved_bom_11_4.dtypes\n",
    "          \n",
    "    ### Encode Train SET of Good BOM SET @@@@@@@@@@@@@@\n",
    "    ESR_approved_bom_11_4 = pd.DataFrame({col: ESR_approved_bom_11_4[col].astype('category').cat.codes for col in ESR_approved_bom_11_4}, index=ESR_approved_bom_11_4.index)\n",
    "    ESR_approved_bom_11_4.dtypes\n",
    "    print(ESR_approved_bom_11_4.head())\n",
    "          \n",
    "    ### Impute Validation SET of Good BOM SET @@@@@@@@@@@@@@\n",
    "    ESR_approved_bom_22.shape\n",
    "    print(ESR_approved_bom_22.isnull().sum())\n",
    "    print(ESR_approved_bom_22.head())\n",
    "\n",
    "    ESR_approved_bom_22.shape\n",
    "    ###################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    perc = 80.0 # Like N %\n",
    "    min_count =  int(((100-perc)/100)*ESR_approved_bom_22.shape[0] + 1)\n",
    "    ESR_approved_bom_22_3 = ESR_approved_bom_22.dropna( axis=1, thresh=min_count)\n",
    "    # DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    ESR_approved_bom_22_3 .shape\n",
    "    print(ESR_approved_bom_22_3 .head())\n",
    "\n",
    "    ##################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    ####################### IMPUTE With Higest Fresq. Value @@@@@@@@@@@@\n",
    "    ESR_approved_bom_22_4=ESR_approved_bom_22_3.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    ESR_approved_bom_22_4.isnull().sum(axis=0)\n",
    "    ESR_approved_bom_22_4.shape\n",
    "    print(ESR_approved_bom_22_4.head())\n",
    "    \n",
    "    ### Encode Validation SET of Good BOM SET @@@@@@@@@@@@@@\n",
    "   # ESR_approved_bom_22_4['DeliverableId']=ESR_approved_bom_22_4.astype({'DeliverableId': 'object'}, copy=True).dtypes\n",
    "    ESR_approved_bom_22_4.dtypes\n",
    "    #ESR_approved_bom_11_4['DeliverableId'].astype('object')\n",
    "    print(ESR_approved_bom_22_4.head())\n",
    "    ESR_approved_bom_22.shape\n",
    "    \n",
    "    ESR_approved_bom_22_4 = pd.DataFrame({col: ESR_approved_bom_22_4[col].astype('category').cat.codes for col in ESR_approved_bom_22_4}, index=ESR_approved_bom_22_4.index)\n",
    "    ESR_approved_bom_22_4.dtypes\n",
    "    print(ESR_approved_bom_22_4.head())\n",
    "\n",
    "    ### IMPUTE Test SET- RETURN BOM SET @@@@@@@@@@@@@@\n",
    "    ESR_approved_bom_22_4.shape\n",
    "    print(ESR_approved_bom_22_4.head())\n",
    "    all_ops_bom_anomalyScore_file_df_3.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.head())\n",
    "          \n",
    "    all_ops_bom_anomalyScore_file_df_3.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.isnull().sum())\n",
    "    print(all_ops_bom_anomalyScore_file_df_3.head())\n",
    "    \n",
    "    ###################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    perc = 80.0 # Like N %\n",
    "    min_count =  int(((100-perc)/100)*all_ops_bom_anomalyScore_file_df_3.shape[0] + 1)\n",
    "    all_ops_bom_anomalyScore_file_df_4_3 = all_ops_bom_anomalyScore_file_df_3.dropna( axis=1, thresh=min_count)\n",
    "    # DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    all_ops_bom_anomalyScore_file_df_4_3.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_3.head())\n",
    "\n",
    "    ##################### dropna with % threshold @@@@@@@@@@@@@@@@@@@@@@@22\n",
    "    ####################### IMPUTE With Higest Fresq. Value @@@@@@@@@@@@\n",
    "    all_ops_bom_anomalyScore_file_df_4_5=all_ops_bom_anomalyScore_file_df_4_3.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    all_ops_bom_anomalyScore_file_df_4_5.isnull().sum(axis=0)\n",
    "    all_ops_bom_anomalyScore_file_df_4_5.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_5.head())\n",
    "          \n",
    "    ### Encode Test SET RETURN BOM SET @@@@@@@@@@@@@@\n",
    "    #all_ops_bom_anomalyScore_file_df_4_5['DeliverableId']=all_ops_bom_anomalyScore_file_df_4_5.astype({'DeliverableId': 'object'}, copy=True).dtypes\n",
    "    all_ops_bom_anomalyScore_file_df_4_5.dtypes\n",
    "          \n",
    "    all_ops_bom_anomalyScore_file_df_4_5 = pd.DataFrame({col: all_ops_bom_anomalyScore_file_df_4_5[col].astype('category').cat.codes for col in all_ops_bom_anomalyScore_file_df_4_5}, index=all_ops_bom_anomalyScore_file_df_4_5.index)\n",
    "    all_ops_bom_anomalyScore_file_df_4_5.dtypes\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_5.head())\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_5.shape, all_ops_bom_anomalyScore_file_df_4_5.columns, all_ops_bom_anomalyScore_file_df_4_5.dtypes)\n",
    "    \n",
    "    #### END of Train/Validate/Test Data Preparation & Feature Engineering @@@@@@@@@@@@@2\n",
    "    \n",
    "    \n",
    "    return ESR_approved_bom_11, ESR_approved_bom_22, ESR_approved_bom_11_4, ESR_approved_bom_22_4, all_ops_bom_anomalyScore_file_df_4_5, all_ops_bom_anomalyScore_file_df, all_ops_bom_anomalyScore_file_df_3\n",
    "\n",
    "def Site_BOM_train_fit(ESR_approved_bom_11_4 , ESR_approved_bom_22_4, all_ops_bom_anomalyScore_file_df_4_5):\n",
    "    #############, ESR_approved_bom_22_4, all_ops_bom_anomalyScore_file_df_4_5\n",
    "    ######################### Declaring Global Variables ######################################\n",
    "    #x_train_rf3_2_b,y_train_rf3_b\n",
    "    global ESR_approved_bom_11_4_hex \n",
    "    global ESR_approved_bom_22_4_hex\n",
    "    global all_ops_bom_anomalyScore_file_df_4_5_hex\n",
    "    global all_ops_bom_anomalyScore_file_df\n",
    "    global all_ops_bom_anomalyScore_file_df_3\n",
    "    global bestModel\n",
    "#     global ESR_approved_bom_11_4\n",
    "#     global ESR_approved_bom_22_4\n",
    "#     global all_ops_bom_anomalyScore_file_df_4_5\n",
    "        \n",
    "    ########################################### Loading Libararies ###############################3\n",
    "    import csv\n",
    "    import glob\n",
    "    import os\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    #pd.set_option('max_columns', None)\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install h2o\n",
    "    import seaborn as sns\n",
    "    #import h2o\n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,Normalizer\n",
    "    #from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize']=15,10\n",
    "\n",
    "    import time\n",
    "    !pip install sklearn --use-feature=2020\n",
    "    start = time.time()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from math import log10, floor\n",
    "    from sklearn import metrics\n",
    "    from statsmodels.distributions.empirical_distribution import ECDF\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    ###############Random Bagging Ensemble- using- Bagging - random sample with replacement, \n",
    "    ## Random sampling using features subsets-Random Sub-Space, & Random sampling- combine both Features \n",
    "    ### & Sample -Random batches ####\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    ########### Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    #import loguniform\n",
    "\n",
    "    ############GBM \n",
    "    #import lightgbm as lgb\n",
    "    ###############\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ####### Cell multiple Display  ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    ####### GridSearch and Skllearn Libraries\n",
    "\n",
    "    #Data Mining\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    #import model_selection \n",
    "    import statsmodels\n",
    "\n",
    "    #Classifier scoring\n",
    "    from sklearn import metrics\n",
    "    import csv\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    # ####### Class Imbalance SMOTE ######\n",
    "    !pip install imblearn\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "    #from StringIO import StringIO\n",
    "    import gzip\n",
    "    #from urllib import urlopen\n",
    "\n",
    "    import requests\n",
    "    #from bs4 import BeautifulSoup\n",
    "    ##os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\sipp')\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "\n",
    "    ##  Code Execution time\n",
    "\n",
    "    import matplotlib.pylab as plt\n",
    "    import statsmodels\n",
    "    %matplotlib inline\n",
    "    from matplotlib.pylab import rcParams\n",
    "    rcParams['figure.figsize'] = 15, 6\n",
    "    import numpy as np; np.random.seed(136)\n",
    "\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    from matplotlib import pylab\n",
    "    from matplotlib import style\n",
    "    import seaborn as sns\n",
    "    sns.set_style('whitegrid')\n",
    "    import seaborn as sns; sns.set(color_codes=True)\n",
    "    from matplotlib import style\n",
    "    style.use('ggplot')\n",
    "    mpl.rcParams['lines.linewidth'] = 2\n",
    "    mpl.rcParams['lines.color'] = 'r'\n",
    "    from numpy import argmax\n",
    "    ########## Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    # import loguniform\n",
    "    # from sklearn.datasets import load_digits\n",
    "    # from sklearn.linear_model import SGDClassifier\n",
    "    # ### Warning messages mode  ####\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    ####### Cell multiple Display Config ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    #path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "    path1=os.getcwd()\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "    ############# Printing Plot output ###############\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    pd.options.display.max_rows = 4000\n",
    "    ############################# Decision Tree Plots & Viz Libs  #####################\n",
    "    import scipy\n",
    "    from sys import getsizeof\n",
    "    from IPython.display import Image\n",
    "    from matplotlib import pylab\n",
    "    from sklearn.tree import _tree\n",
    "    #from skrules import SkopeRules\n",
    "    ###### Accuracy Paramters\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "    import unittest\n",
    "    ## range to xrange copatability in python 2 &#3\n",
    "#     try:\n",
    "#     # Python 2 forward compatibility\n",
    "#     range = xrange\n",
    "#     except NameError:\n",
    "#     pass\n",
    "\n",
    "    #####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "    import future  , builtins , past, six      \n",
    "    from six import reraise as raise_\n",
    "    from future.utils import raise_\n",
    "\n",
    "    ###################### Model Pickling & JSON Support Loads #################\n",
    "    import pickle\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    import base64\n",
    "    import string\n",
    "    import re\n",
    "    #############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # import gensim\n",
    "    import os\n",
    "    import collections\n",
    "    # import smart_open\n",
    "    import random\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    ###################### IMPORT MODEL JOBLIB @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "\n",
    "    #from __future__ import print_function\n",
    "\n",
    "    import json\n",
    "\n",
    "    import traceback\n",
    "    import time\n",
    "    import socket\n",
    "    from collections import Counter\n",
    "\n",
    "    !conda install -c conda-forge h2o-py openjdk -y\n",
    "\n",
    "    #import boto3\n",
    "    from   IPython                   import display\n",
    "    import matplotlib.pyplot         as plt\n",
    "    # import sagemaker\n",
    "    # from sagemaker.tensorflow import TensorFlow\n",
    "    # from sagemaker.tensorflow.serving import Model, Predictor\n",
    "    # from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "    # from   sklearn.decomposition     import PCA\n",
    "    # #!pip install pytest-astropy    ############# Prequisite for Tensorflow install\n",
    "    !pip install tensorflow\n",
    "    import tensorflow                as tf\n",
    "    from   tensorflow                import keras\n",
    "    from   tensorflow.keras.datasets import mnist\n",
    "    import tensorflow.keras.backend  as K\n",
    "    import time\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from scipy       import stats\n",
    "    from statistics  import mean\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    import h2o\n",
    "    #Dsys.ai.h2o.util.frameSizeMonitor.enabled=True\n",
    "    #h2o.shutdown()\n",
    "    h2o.init(port=54321)\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "    import h2o as ml\n",
    "    from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    ml.init()\n",
    "    \n",
    "    from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    \n",
    "    ################################## H2O AUTOENCODER MODEL Hyperparamters @@@@@@@@@@@@@@@@@@@@@\n",
    "    \n",
    "    ####################### H2O MODEL LOAD @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    \n",
    "#     model= H2OAutoEncoderEstimator(activation=\"Tanh\",\n",
    "#                               hidden=[120],\n",
    "#                               ignore_const_cols=False,\n",
    "#                               epochs=100)\n",
    "    \n",
    "    \n",
    "    ################ Conversion of Pandad DF to H2O DF's @@@@@@@@@@@@@@@@@@@@@@@@2\n",
    "    # h2o.H2OFrame(ESR_approved_bom_11_4.values.tolist())   # get no header\n",
    "    # ESR_approved_bom_11_4_hex= h2o.H2OFrame(ESR_approved_bom_11_4.to_dict())           # out-of-order cols due to python dict\n",
    "    #ESR_approved_bom_11_4=pd.read_csv(r's3://bom-anomaly-detection/Train_set/prepared-trainSet/ESR_approved_bom_11_4.csv',sep=',',  encoding=\"utf-8-sig\", index_col=0)\n",
    "    #ESR_approved_bom_11_4.shape\n",
    "    ESR_approved_bom_11_4_hex=h2o.H2OFrame(ESR_approved_bom_11_4)  ###########train SET\n",
    "    print(ESR_approved_bom_11_4_hex)\n",
    "\n",
    "    #ESR_approved_bom_22_4=pd.read_csv(r's3://bom-anomaly-detection/validation_set/validate_preparedSet/ESR_approved_bom_22_4.csv',sep=',',  encoding=\"utf-8-sig\", index_col=0)\n",
    "    #ESR_approved_bom_22_4.shape\n",
    "    ESR_approved_bom_22_4_hex=h2o.H2OFrame(ESR_approved_bom_22_4)  ############# Validation SET\n",
    "    print(ESR_approved_bom_22_4_hex)\n",
    "\n",
    "    #all_ops_bom_anomalyScore_file_df_4_5=pd.read_csv(r's3://bom-anomaly-detection/bom_anom_test_set/test_preparedSet/all_ops_bom_anomalyScore_file_df_4_5.csv',sep=',',  encoding=\"utf-8-sig\", index_col=0)\n",
    "    #all_ops_bom_anomalyScore_file_df_4_5.shape\n",
    "    all_ops_bom_anomalyScore_file_df_4_5_hex=h2o.H2OFrame(all_ops_bom_anomalyScore_file_df_4_5)  ############# Validation SET\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_5_hex)\n",
    "    ##################### Print H2O DF's @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    print(ESR_approved_bom_11_4.shape, ESR_approved_bom_22_4.shape, all_ops_bom_anomalyScore_file_df_4_5.shape)\n",
    "    print(ESR_approved_bom_11_4.head())\n",
    "    print(ESR_approved_bom_22_4.head())\n",
    "    print(all_ops_bom_anomalyScore_file_df_4_5.head())\n",
    "    \n",
    "    #################################### BEGIING of GRID SEARCH FOR HYPERPARAMTERS TUNING @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from h2o.grid.grid_search import H2OGridSearch\n",
    "    #grid_search_gbm = H2OAutoEncoderEstimator(ignore_const_cols=False, seed=1234)\n",
    "    #grid_search_auto = H2OAutoEncoderEstimator( ignore_const_cols=False, activation=\"Tanh\",epochs=200)\n",
    "    grid_search_auto = H2OAutoEncoderEstimator(ignore_const_cols=False, activation=\"Tanh\")\n",
    "    #activation=\"Tanh\",   ### setup via Grid Search to select the best activation Functio\n",
    "    ### ,seed=1234\n",
    "    #grid_search_gbm = H2OAutoEncoderEstimator(ignore_const_cols=False, stopping_rounds = 500, stopping_metric = \"mse\")\n",
    "    ## seed = RANDOM_STATE  ## used for GBM not autoecndoder @@@@@@@@@@@@@\n",
    "    ####### stopping_metric = \"mse\", ## used for GBM not autoecndoder @@@@@@@@@@@@@\n",
    "\n",
    "    hiddenOpt = [[50,50],[120,120], [200,200]]\n",
    "    ### , [5,5,5],[50,50,50] ### LEave for second round of hyperparams tunning!\n",
    "    l2Opt = [1e-4,1e-2]\n",
    "    #activations= ['Tanh', 'relu', 'sigmoid']\n",
    "    #learn_rates=[0.001, 0.01, 0.02]  ############ not supported with autoencoder\n",
    "    epochs_1 = [200,400]    ############ cause hugh delay in training \n",
    "    ## ,  'epochs':epochs_1\n",
    "    hyperParameters_1 = {\"hidden\":hiddenOpt, \"l2\":l2Opt, \"epochs\":epochs_1}\n",
    "    # , \"activation\": activations\n",
    "    # hyper_params = {\n",
    "    #     #'activation' : ['Tanh', 'relu', 'sigmoid'],\n",
    "    #       'hidden': [64, 128, 256, 512 ],\n",
    "    #     'learn_rate':[0.001, 0.01, 0.02],\n",
    "    #      #ignore_const_cols=False,\n",
    "    #       'epochs' :[100,200, 300, 500]\n",
    "    #      ######## End of Autecondoer hyperparams@@@@@@@@@@@@@\n",
    "    #     }\n",
    "    # 'learn_rate':[0.01, 0.02, 0.03], used example from GBM\n",
    "    #     'max_depth':[4,8,16,24],\n",
    "    #     'ntrees':[50, 250, 1000]\n",
    "\n",
    "    # model = H2OGridSearch(grid_search_auto, hyperParameters_1,\n",
    "    #                          grid_id='depth_grid',\n",
    "    #                          search_criteria={'strategy': \"Cartesian\"})\n",
    "    model = H2OGridSearch(grid_search_auto, hyperParameters_1)\n",
    "    fs1= list(ESR_approved_bom_11_4.columns)\n",
    "    fs1\n",
    "    #Train grid search\n",
    "    model.train(x=fs1,training_frame=ESR_approved_bom_11_4_hex)\n",
    "    ############## Select Best Model with Least MSE @@@@@@@@@@@@@@@@@@@\n",
    "    gridperf1 = model.get_grid(sort_by='mse', decreasing=True)\n",
    "    bestModel = gridperf1.models[0]\n",
    "\n",
    "################################ END of GRID SEARCH HYPERPARAMTERS TUNING @@@@@@@@@@@@@@@@@@@@@@\n",
    "    \n",
    "    return ESR_approved_bom_11_4_hex , ESR_approved_bom_22_4_hex, all_ops_bom_anomalyScore_file_df_4_5_hex, bestModel,all_ops_bom_anomalyScore_file_df, all_ops_bom_anomalyScore_file_df_3\n",
    "   \n",
    "    ############################################### END of MODEL FIT & CLASSIFCATION Perforamnce TEST ###############\n",
    "    ###########################  NEXT IS USAGE of MODEL TO SCORE PRODUCTION DATA FOr Nodes Failures Prediction #####\n",
    "    \n",
    "def node_fault_scoring(ESR_approved_bom_11_4_hex, ESR_approved_bom_22_4_hex, all_ops_bom_anomalyScore_file_df_4_5_hex):\n",
    "    # , x_train_rf3, b_node_xgb_8b, y_train_rf3\n",
    "    #def node_fault_scoring(b_node_xgb_8b, raw_data, upgrade_actual, path_to_upgrade):\n",
    "    \n",
    "    ######################### Declaring Global Variables ######################################\n",
    "    #global path_to_upgrade\n",
    "#     global ESR_approved_bom_11_4_hex \n",
    "#     global ESR_approved_bom_22_4_hex\n",
    "#     global all_ops_bom_anomalyScore_file_df_4_5_hex\n",
    "    \n",
    "    global ESR_approved_bom_11_4\n",
    "    global ESR_approved_bom_22_4\n",
    "    global all_ops_bom_anomalyScore_file_df_4_5\n",
    "    global all_ops_bom_anomalyScore_file_df    \n",
    "    global all_ops_bom_anomalyScore_file_df_3\n",
    "    global bestModel\n",
    "    \n",
    "    ########################################### Loading Libararies ###############################3\n",
    "    import csv\n",
    "    import glob\n",
    "    import os\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    from pandas import concat\n",
    "    #pd.set_option('max_columns', None)\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install h2o\n",
    "    import seaborn as sns\n",
    "    #import h2o\n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,Normalizer\n",
    "    #from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "    from pylab import rcParams\n",
    "    rcParams['figure.figsize']=15,10\n",
    "\n",
    "    import time\n",
    "    !pip install sklearn --use-feature=2020\n",
    "    start = time.time()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from math import log10, floor\n",
    "    from sklearn import metrics\n",
    "    from statsmodels.distributions.empirical_distribution import ECDF\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    ###############Random Bagging Ensemble- using- Bagging - random sample with replacement, \n",
    "    ## Random sampling using features subsets-Random Sub-Space, & Random sampling- combine both Features \n",
    "    ### & Sample -Random batches ####\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    ########### Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    #import loguniform\n",
    "\n",
    "    ############GBM \n",
    "    #import lightgbm as lgb\n",
    "    ###############\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ####### Cell multiple Display  ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    ####### GridSearch and Skllearn Libraries\n",
    "\n",
    "    #Data Mining\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    #from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    #import model_selection \n",
    "    import statsmodels\n",
    "\n",
    "    #Classifier scoring\n",
    "    from sklearn import metrics\n",
    "    import csv\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "\n",
    "    # ####### Class Imbalance SMOTE ######\n",
    "    !pip install imblearn\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "    #from StringIO import StringIO\n",
    "    import gzip\n",
    "    #from urllib import urlopen\n",
    "\n",
    "    import requests\n",
    "    #from bs4 import BeautifulSoup\n",
    "    ##os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\sipp')\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "\n",
    "    ##  Code Execution time\n",
    "\n",
    "    import matplotlib.pylab as plt\n",
    "    import statsmodels\n",
    "    %matplotlib inline\n",
    "    from matplotlib.pylab import rcParams\n",
    "    rcParams['figure.figsize'] = 15, 6\n",
    "    import numpy as np; np.random.seed(136)\n",
    "\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    from matplotlib import pylab\n",
    "    from matplotlib import style\n",
    "    import seaborn as sns\n",
    "    sns.set_style('whitegrid')\n",
    "    import seaborn as sns; sns.set(color_codes=True)\n",
    "    from matplotlib import style\n",
    "    style.use('ggplot')\n",
    "    mpl.rcParams['lines.linewidth'] = 2\n",
    "    mpl.rcParams['lines.color'] = 'r'\n",
    "    from numpy import argmax\n",
    "    ########## Importing sklearn Stats\n",
    "    import scipy.stats as stats\n",
    "    # import loguniform\n",
    "    # from sklearn.datasets import load_digits\n",
    "    # from sklearn.linear_model import SGDClassifier\n",
    "    # ### Warning messages mode  ####\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    ####### Cell multiple Display Config ##\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "    ## turning off depracation messages\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    #path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "    path1=os.getcwd()\n",
    "    #os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "    print(os.getcwd())\n",
    "\n",
    "    ############# Printing Plot output ###############\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    pd.options.display.max_rows = 4000\n",
    "    ############################# Decision Tree Plots & Viz Libs  #####################\n",
    "    import scipy\n",
    "    from sys import getsizeof\n",
    "    from IPython.display import Image\n",
    "    from matplotlib import pylab\n",
    "    from sklearn.tree import _tree\n",
    "    #from skrules import SkopeRules\n",
    "    ###### Accuracy Paramters\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "    import unittest\n",
    "    ## range to xrange copatability in python 2 &#3\n",
    "#     try:\n",
    "#     # Python 2 forward compatibility\n",
    "#     range = xrange\n",
    "#     except NameError:\n",
    "#     pass\n",
    "\n",
    "    #####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "    import future  , builtins , past, six      \n",
    "    from six import reraise as raise_\n",
    "    from future.utils import raise_\n",
    "\n",
    "    ###################### Model Pickling & JSON Support Loads #################\n",
    "    import pickle\n",
    "    import requests\n",
    "    import json\n",
    "\n",
    "    import base64\n",
    "    import string\n",
    "    import re\n",
    "    #############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # from smart_open import open\n",
    "    # from smart_open import s3_iter_bucket\n",
    "    # import gensim\n",
    "    import os\n",
    "    import collections\n",
    "    # import smart_open\n",
    "    import random\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    ###################### IMPORT MODEL JOBLIB @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "\n",
    "    #from __future__ import print_function\n",
    "\n",
    "    import json\n",
    "\n",
    "    import traceback\n",
    "    import time\n",
    "    import socket\n",
    "    from collections import Counter\n",
    "\n",
    "    !conda install -c conda-forge h2o-py openjdk -y\n",
    "\n",
    "    #import boto3\n",
    "    from   IPython                   import display\n",
    "    import matplotlib.pyplot         as plt\n",
    "    # import sagemaker\n",
    "    # from sagemaker.tensorflow import TensorFlow\n",
    "    # from sagemaker.tensorflow.serving import Model, Predictor\n",
    "    # from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "    # from   sklearn.decomposition     import PCA\n",
    "    # #!pip install pytest-astropy    ############# Prequisite for Tensorflow install\n",
    "    !pip install tensorflow\n",
    "    import tensorflow                as tf\n",
    "    from   tensorflow                import keras\n",
    "    from   tensorflow.keras.datasets import mnist\n",
    "    import tensorflow.keras.backend  as K\n",
    "    import time\n",
    "    from scipy.stats import multivariate_normal\n",
    "    from scipy       import stats\n",
    "    from statistics  import mean\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "          \n",
    "    ################################### Predict Anomalies @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "#     model= H2OAutoEncoderEstimator(activation=\"Tanh\",  ############ Already fitted at fit funciton above @@@@@2\n",
    "#                               hidden=[120],\n",
    "#                               ignore_const_cols=False,\n",
    "#                               epochs=100)\n",
    "    \n",
    "    ############# Create Train List @@@@@@@@@@@@@@@@@@@@@@\n",
    "    fs1= list(ESR_approved_bom_11_4.columns)\n",
    "    fs1\n",
    "    ############################# FIT AUTOENCODER MODEL @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    #bestModel.train(x=fs1,training_frame=ESR_approved_bom_11_4_hex)  @@@@@@@ Already trained at fit function phase ###\n",
    "    ################### Prdict ANomalies @@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    Test_rec_error=bestModel.anomaly(all_ops_bom_anomalyScore_file_df_4_5_hex)\n",
    "    Train_rec_error=bestModel.anomaly(ESR_approved_bom_11_4_hex)\n",
    "    Validate_rec_error=bestModel.anomaly(ESR_approved_bom_22_4_hex)\n",
    "    \n",
    "    # #### PRINT RESULTS @@@@@@@@@@@@@@@@\n",
    "\n",
    "    Test_rec_error.shape\n",
    "    print(Test_rec_error)\n",
    "    all_ops_bom_anomalyScore_file_df_4_5.shape\n",
    "\n",
    "    Train_rec_error.shape\n",
    "    print(Train_rec_error)\n",
    "    ESR_approved_bom_11_4.shape\n",
    "\n",
    "    Validate_rec_error.shape\n",
    "    print(Validate_rec_error)\n",
    "    ESR_approved_bom_22_4.shape\n",
    "          \n",
    "    ### Print Contribution of Each BOM Feature in RETURN BOM Items Anomaly Predictions- A Proxy\n",
    "    #### For Return Reason in BOM Return Request Justification @@@@@@@@@@@@@@@@@\n",
    "    \n",
    "    BOM_anom_fs_cont_1=bestModel.anomaly(all_ops_bom_anomalyScore_file_df_4_5_hex, per_feature=True)\n",
    "    BOM_anom_fs_cont_df_2 = BOM_anom_fs_cont_1.as_data_frame().reset_index()\n",
    "    print(BOM_anom_fs_cont_df_2.shape,BOM_anom_fs_cont_df_2.head())\n",
    "          \n",
    "    ### BOM Anomaly Prediction & Explanation TO GENETATE the FINAL BOM ANOMALY List @@@@@\n",
    "    ##### to Be Sent Over to ESR Team Prior to BOM Approval @@@@@@@@@\n",
    "    \n",
    "    BOM_anom_fs_cont_df_2.shape\n",
    "    BOM_anom_fs_cont_df_2.columns\n",
    "\n",
    "          \n",
    "    ########################## CREATE INDEX for BOM @@@@@@@@@@@@@@@@@@@@@\n",
    "    BOM_anom_fs_cont_df_2['index_col'] = range(0, len(BOM_anom_fs_cont_df_2))\n",
    "    all_ops_bom_anomalyScore_file_df['index_col'] = range(0, len(all_ops_bom_anomalyScore_file_df))\n",
    "\n",
    "    Return_BOM_FeatureAnalysis_2  = all_ops_bom_anomalyScore_file_df.merge(BOM_anom_fs_cont_df_2, on=['index_col'] ,how='inner')\n",
    "    Return_BOM_FeatureAnalysis_2.shape\n",
    "    Return_BOM_FeatureAnalysis_2.columns\n",
    "    print(Return_BOM_FeatureAnalysis_2.head())\n",
    "    \n",
    "    ### In the Following BOM ANOMALY CLASSIFICATION & ANOMALY CLassification @@@\n",
    "    ### Will be Computed Then The Results Will be Merged With Anomaly Weights @@@ \n",
    "    ## Above to Generate the Final Anomaly List @@@\n",
    "    #### Conversion of H2O Dataframe set Pandas DF DataFrame @@@@@@@@@@@@@@@\n",
    "    \n",
    "    import h2o\n",
    "    #Dsys.ai.h2o.util.frameSizeMonitor.enabled=True\n",
    "    #h2o.shutdown()\n",
    "    h2o.init(port=54321)\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "    ################### Return BOM set Conversion to DF from H2O Frame @@@@@@@@@@@@@@@\n",
    "    Test_rec_error_df = h2o.as_list(Test_rec_error)\n",
    "    Test_rec_error_df.shape\n",
    "    print(Test_rec_error.head())\n",
    "\n",
    "    ################### Train BOM set Conversion to DF from H2O Frame @@@@@@@@@@@@@@@\n",
    "    Train_rec_error_df = h2o.as_list(Train_rec_error)\n",
    "    Train_rec_error_df.shape\n",
    "    print(Train_rec_error.head())\n",
    "\n",
    "    ################### Validation BOM set Conversion to DF from H2O Frame @@@@@@@@@@@@@@@\n",
    "    Validate_rec_error_df = h2o.as_list(Validate_rec_error)\n",
    "    Validate_rec_error_df.shape\n",
    "    print(Validate_rec_error_df.head())\n",
    "    \n",
    "    #### 99.9% BOM ANomaly Threhold For Train SET GOOD ESR BOM- Using Seven FS MODEL ################\n",
    "          \n",
    "    !pip install -U seaborn\n",
    "    import tensorflow as tf\n",
    "    # reconstruct_loss_train= tf.keras.losses.mae(good_bom_pred_train_2, ESR_approved_bom_11)\n",
    "    loss_threshold_train_h20  = np.percentile(Train_rec_error_df, 99.9)\n",
    "    print(f'The Reconstruction error loss Threshold for Train Top 1% of Anomalous BOM is{loss_threshold_train_h20 :.3f}')\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(20, 10)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #plt.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.displot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    Train_rec_error_df.hist( bins=30, alpha=0.8)\n",
    "    plt.axvline(x= loss_threshold_train_h20, color='orange')\n",
    "    plt.title(\"Seven FS H2O Model ESR Good Train BOM Reconstruction Error Threhold Top 2%\")\n",
    "    plt.xlabel(\"Seven FS Combined SCALED H2O Model Train BOM Construction Error\")\n",
    "    fig.savefig( os.path.join ('Seven_FS_H2O_Model_Train_Error_Threhold_99pct.png'), dpi=100)\n",
    "    \n",
    "    #### 99.9% BOM ANomaly Threhold For -Validation  SET ESR GOOD BOM- Using Seven FS MODEL ################\n",
    "    #!pip install -U seaborn\n",
    "    import tensorflow as tf\n",
    "    # reconstruct_loss_train= tf.keras.losses.mae(good_bom_pred_train_2, ESR_approved_bom_11)\n",
    "    loss_threshold_validate_h20  = np.percentile(Validate_rec_error_df, 99.9)\n",
    "    print(f'The Reconstruction error loss Threshold for Validation Top 1% of Anomalous BOM is{loss_threshold_validate_h20:.3f}')\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(20, 10)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #plt.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.displot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    Validate_rec_error_df.hist( bins=30, alpha=0.8)\n",
    "    plt.axvline(x= loss_threshold_validate_h20, color='orange')\n",
    "    plt.title(\"Seven FS H2O Model ESR Validation GOOD BOM Reconstruction Error Threhold Top 1%\")\n",
    "    plt.xlabel(\"Seven FS H2O Model Validation BOM Construction Error\")\n",
    "    fig.savefig( os.path.join ('Seven_FS_H2O_Model_Validation_Error_Threhold_99pct.png'), dpi=100)\n",
    "    BOM_anom_fs_cont_df_2.head()\n",
    "    BOM_anom_fs_cont_df_2.shape\n",
    "    \n",
    "    #### 99.9 % BOM ANomaly Threhold For TEST  SET ESR Return BAD BOM- Using Seven FS MODEL ################\n",
    "    import tensorflow as tf\n",
    "    # reconstruct_loss_train= tf.keras.losses.mae(good_bom_pred_train_2, ESR_approved_bom_11)\n",
    "    loss_threshold_test_h20  = np.percentile(Test_rec_error_df, 99.9)\n",
    "    print(f'The Reconstruction error loss Threshold for Test Top 1% of Anomalous BOM is{loss_threshold_test_h20:.3f}')\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(20, 10)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #fig, axes = plt.plot( figsize=(20,18), constrained_layout=True)\n",
    "    #plt.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.histplot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    #sns.displot(BOM_anom_fs_cont_df_2, bins=30, alpha=0.8)\n",
    "    Test_rec_error_df.hist( bins=30, alpha=0.8)\n",
    "    plt.axvline(x=loss_threshold_test_h20 , color='orange')\n",
    "    plt.title(\"Seven FS H2O Model ESR Test Bad Return BOM Reconstruction Error Threhold Top 1%\")\n",
    "    plt.xlabel(\"Seven FS H2O Model Test BOM Construction Error\")\n",
    "    fig.savefig( os.path.join ('Seven_FS_H2O_Model_Test_Error_Threhold_99pct.png'), dpi=100)\n",
    "    \n",
    "    Test_rec_error_df.shape\n",
    "    print(Test_rec_error_df.head())\n",
    "    all_ops_bom_anomalyScore_file_df.shape\n",
    "    print(all_ops_bom_anomalyScore_file_df.head())\n",
    "    \n",
    "    ###### Train Classification Report START @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@2\n",
    "    ESR_approved_bom_11['BOM_STATUS']='Approved_Normal'\n",
    "    ESR_approved_bom_11['BOM_STATUS_Binary']=0\n",
    "\n",
    "    ESR_approved_bom_11.shape\n",
    "    print(ESR_approved_bom_11.head())\n",
    "    \n",
    "    ESR_approved_bom_11.shape\n",
    "    train_target=ESR_approved_bom_11['BOM_STATUS_Binary']\n",
    "    train_target.shape\n",
    "    train_target.dtypes\n",
    "    print(train_target.head())\n",
    "    \n",
    "    ### Step 2: CONVERT TRAIN BOM Reconstruction Error From Scientific to FLOAT @@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "    Train_rec_error_df_3=Train_rec_error_df.apply(lambda x: '%.5f' % x, axis=1)\n",
    "    print(Train_rec_error_df_3.head())\n",
    "    Train_rec_error_df_3= Train_rec_error_df_3.astype('float64')\n",
    "    Train_rec_error_df_3.dtypes\n",
    "    \n",
    "    Train_ESR_Bom_anom_scores_T = [0 if i <  loss_threshold_validate_h20 else 1 for  i in Train_rec_error_df_3] ### Using Top Reconstruct. errors PCNT for GOOD BOM###\n",
    "    ################# Convert List to Dataframe @@@@@@@@@@@@@@@@@@@\n",
    "    Train_ESR_Bom_anom_Threhold_df_T = pd.DataFrame(Train_ESR_Bom_anom_scores_T, columns = ['BOM_Anomaly_Predicted'])\n",
    "    #Train_ESR_Bom_anom_Threhold_df = Train_ESR_\n",
    "    Train_ESR_Bom_anom_Threhold_df_T.astype(int)\n",
    "    Train_ESR_Bom_anom_Threhold_df_T.shape\n",
    "    print (Train_ESR_Bom_anom_Threhold_df_T.head())\n",
    "    Train_ESR_Bom_anom_Threhold_df_T.dtypes\n",
    "    print(classification_report(Train_ESR_Bom_anom_Threhold_df_T[0:6105361], train_target[0:6105361]))\n",
    "    Train_ESR_Bom_anom_Threhold_df_T['BOM_Anomaly_Predicted'].value_counts(\"Y\")\n",
    "    \n",
    "    ###### Validation Classification Report START @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@2\n",
    "    ESR_approved_bom_22['BOM_STATUS']='Approved_Normal'\n",
    "    ESR_approved_bom_22['BOM_STATUS_Binary']=0\n",
    "\n",
    "    ESR_approved_bom_22.shape\n",
    "    print(ESR_approved_bom_22.head())\n",
    "    \n",
    "    ESR_approved_bom_22.shape\n",
    "    val_target=ESR_approved_bom_22['BOM_STATUS_Binary']\n",
    "    val_target.shape\n",
    "    val_target.dtypes\n",
    "    print(val_target.head())\n",
    "    \n",
    "    ### Step 2: CONVERT TRAIN BOM Reconstruction Error From Scientific to FLOAT @@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "    Validate_rec_error_df_3= Validate_rec_error_df.apply(lambda x: '%.5f' % x, axis=1)\n",
    "    print(Validate_rec_error_df_3.head())\n",
    "    Validate_rec_error_df_3=  Validate_rec_error_df_3.astype('float64')\n",
    "    Validate_rec_error_df_3.dtypes\n",
    "    \n",
    "    Val_ESR_Bom_anom_scores_T = [0 if i <  loss_threshold_validate_h20 else 1 for  i in Validate_rec_error_df_3] ### Using Top Reconstruct. errors PCNT for GOOD BOM###\n",
    "    ################# Convert List to Dataframe @@@@@@@@@@@@@@@@@@@\n",
    "    Val_ESR_Bom_anom_scores_df_T = pd.DataFrame(Val_ESR_Bom_anom_scores_T, columns = ['BOM_Anomaly_Predicted'])\n",
    "    #Train_ESR_Bom_anom_Threhold_df = Train_ESR_\n",
    "    Val_ESR_Bom_anom_scores_df_T.astype(int)\n",
    "    Val_ESR_Bom_anom_scores_df_T.shape\n",
    "    print (Train_ESR_Bom_anom_Threhold_df_T.head())\n",
    "    Val_ESR_Bom_anom_scores_df_T.dtypes\n",
    "    l1=len(val_target)\n",
    "    print(classification_report(Val_ESR_Bom_anom_scores_df_T[0:l1], val_target[0:l1]))\n",
    "    #3093787, 3093786\n",
    "    Val_ESR_Bom_anom_scores_df_T['BOM_Anomaly_Predicted'].value_counts(\"Y\")\n",
    "    \n",
    "    ######################################## END of Train CLassification @@@@@@@@@@@@@@@@@@@@@@\n",
    "   \n",
    "    #### CLASSIFICATION REPORT For RETURN BOM @@@@@@@@@@@@@\n",
    "    all_ops_bom_anomalyScore_file_df['BOM_STATUS_Binary']=1\n",
    "    all_ops_bom_anomalyScore_file_df['BOM_STATUS_Binary'].shape\n",
    "    print(all_ops_bom_anomalyScore_file_df['BOM_STATUS_Binary'].head())\n",
    "    \n",
    "    ###  Step 1: Convert Threhod to Flaot & DF Before IF Comparison @@@@@@@@@@@@@@@@@@@@@@@\n",
    "    loss_threshold_validate_h20 = np.array(loss_threshold_validate_h20).item()\n",
    "    loss_threshold_validate_h20\n",
    "\n",
    "    ### Step 2: CONVERT Return BOM Reconstruction Error From Scientific to FLOAT @@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "    Test_rec_error_df_3=Test_rec_error_df.apply(lambda x: '%.5f' % x, axis=1)\n",
    "    print(Test_rec_error_df_3.head())\n",
    "    Test_rec_error_df_3=Test_rec_error_df_3.astype('float64')\n",
    "    Test_rec_error_df_3.dtypes\n",
    "    \n",
    "    ### Step 3: Create the Retun BOM Anomaly Target- Actual to Compare to Predicted to Compute Model Classofocation Accuracy @@@@@@@@@@@\n",
    "    bom_target =all_ops_bom_anomalyScore_file_df['BOM_STATUS_Binary']\n",
    "    bom_target = bom_target.astype(int)\n",
    "    print(bom_target.head())\n",
    "    bom_target.dtypes\n",
    "    bom_target.shape\n",
    "\n",
    "    ### Step 4: Compute Anomaly Results Column based on Validation Construction Error at 99.9% Percentile @@@@@@\n",
    "    Bad_Bom_anom_Threhold= [0 if i < loss_threshold_validate_h20 else 1 for  i in Test_rec_error_df_3] ### Using Top Reconstruct. errors PCNT for GOOD BOM###\n",
    "\n",
    "    ################# Convert List to Dataframe @@@@@@@@@@@@@@@@@@@\n",
    "    Bad_Bom_anom_Threhold_df = pd.DataFrame (Bad_Bom_anom_Threhold, columns = ['BOM_Anomaly_Predicted'])\n",
    "    Bad_Bom_anom_Threhold_df = Bad_Bom_anom_Threhold_df.astype(int)\n",
    "    Bad_Bom_anom_Threhold_df.shape\n",
    "    print (Bad_Bom_anom_Threhold_df.head())\n",
    "    Bad_Bom_anom_Threhold_df.dtypes\n",
    "    print(classification_report(bom_target,Bad_Bom_anom_Threhold_df))\n",
    "    Bad_Bom_anom_Threhold_df['BOM_Anomaly_Predicted'].value_counts()\n",
    "    \n",
    "    Bad_Bom_anom_Threhold_df['index_col'] = range(0, len(Bad_Bom_anom_Threhold_df))\n",
    "    print(Bad_Bom_anom_Threhold_df.head())\n",
    "    \n",
    "    ################### Merge the Two Set to Generate the Final BOM Anoma;y Resuts @@@@@@@@@@@@@@@@@@@@@\n",
    "    Return_BOM_FeatureAnalysis_4  = all_ops_bom_anomalyScore_file_df.merge(Bad_Bom_anom_Threhold_df, on=['index_col'] ,how='inner')\n",
    "    Return_BOM_FeatureAnalysis_4.shape\n",
    "    Return_BOM_FeatureAnalysis_4.columns\n",
    "    print(Return_BOM_FeatureAnalysis_4.head())\n",
    "    \n",
    "    #### Dispaly BOM Anomaly Features Weights @@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    BOM_anom_fs_cont_df_2.shape\n",
    "    BOM_anom_fs_cont_df_2.columns\n",
    "    \n",
    "    ### BOM ANOMALY SCORE Appending to Origianl BOM Set @@@@@@@@@@@@@@@\n",
    "    ############### CREATE A BOM ANOMLAY RAW SCORE @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    Return_BOM_FeatureAnalysis_4['BOM_Anomaly_Score']=Test_rec_error_df\n",
    "    Return_BOM_FeatureAnalysis_4.shape\n",
    "    print(Return_BOM_FeatureAnalysis_4.head())\n",
    "    \n",
    "    ### CREATION of the FINAL BOM ANOMALY Generated List With Source of Anomaly Analysis @@@@@@\n",
    "    ### Merging With Weights BOM Anomaly Weights Analysis @@@@@@@@@@@@@@@@@@\n",
    "    Return_BOM_FeatureAnalysis_5  = Return_BOM_FeatureAnalysis_4.merge(BOM_anom_fs_cont_df_2, on=['index_col'] ,how='inner')\n",
    "    \n",
    "    #### First Rename BOM Features REcosntructon Errors to WEIGHTS INSTEAD of Error.SE @@@@@@@@@@@@@2\n",
    "    ############## RENAMING Features - Weights  By Replacing  the Reconstruction Error  & SE Part with Weights @@@@@@@@@@@@@\n",
    "    Return_BOM_FeatureAnalysis_5.rename(columns={'reconstr_DiscriminatorAggrBom.SE': 'DiscriminatorAggrBom_Weight', \\\n",
    "    'reconstr_ProductNumber.SE': 'ProductNumber_Weight',\\\n",
    "    'reconstr_MaterialCategoryAggrBom.SE': 'MaterialCategoryAggrBom_Weight',\\\n",
    "    'reconstr_QuantityAggregatedBom.SE': 'QuantityAggregatedBom_Weight' ,\\\n",
    "    'reconstr_SourcingProviderAggrBom.SE': 'SourcingProviderAggrBom_Weight',\\\n",
    "    'reconstr_ProductDescription.SE': 'ProductDescription_Weight'}, inplace=True)\n",
    "    print(Return_BOM_FeatureAnalysis_5.shape, Return_BOM_FeatureAnalysis_5.columns,Return_BOM_FeatureAnalysis_5.head())\n",
    "    \n",
    "    #### Display The Final BOM Anomaly Detection Complete Output - 44 FEATURES @@@@@@@@@@@@@@@\n",
    "    Return_BOM_FeatureAnalysis_5.shape\n",
    "    print(Return_BOM_FeatureAnalysis_5.head())\n",
    "    Return_BOM_FeatureAnalysis_5.columns\n",
    "    Return_BOM_FeatureAnalysis_5.dtypes\n",
    "    \n",
    "    ### GENERATE the BOM ANOMALY LIST ONLY @@@@@@@@@@@@@@@@@@@@@@@@@@@@@ \n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final=Return_BOM_FeatureAnalysis_5.loc[(Return_BOM_FeatureAnalysis_5['BOM_Anomaly_Predicted']== 1) | (Return_BOM_FeatureAnalysis_5['BOM_Anomaly_Predicted']== 0)]\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final.shape\n",
    "    print(BOM_Anomaly_OnlyList_withAnomalyWeights_Final.head())\n",
    "    \n",
    "    ### WRIING THE FIANL BOM ANOMALY PRIOR TO CAUSES of ANOMALY IS IDENTIFED @@@@@@@@\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final.to_csv(\"BOM_Anomaly_OnlyList_withAnomalyWeights_Final_1\" + timestr + '.csv')\n",
    "    \n",
    "          \n",
    "    ### Determine The Highest BOM Feature Weight in BOM Anomaly Detection @@@@@@@@@@@@@\n",
    "    \n",
    "    bom_dct = {'DiscriminatorAggrBom_Weight':'DiscriminatorAggrBom_Anomaly',\n",
    "       'ProductNumber_Weight': 'ProductNumber_Anomaly', 'MaterialCategoryAggrBom_Weight': 'MaterialCategory_Anomaly',\n",
    "        'QuantityAggregatedBom_Weight':'QuantityAggregatedBom_Anomaly',\n",
    "        'SourcingProviderAggrBom_Weight':'SourcingProvider_Anomaly', 'ProductDescription_Weight':'ProductDescription_Anomaly'}\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final['Likely Cause of Anomaly'] = BOM_Anomaly_OnlyList_withAnomalyWeights_Final[[\n",
    "       'DiscriminatorAggrBom_Weight', 'ProductNumber_Weight', 'MaterialCategoryAggrBom_Weight',\n",
    "        'QuantityAggregatedBom_Weight',\n",
    "       'SourcingProviderAggrBom_Weight', 'ProductDescription_Weight']].idxmax(axis=1).map(bom_dct)\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final.shape\n",
    "    print(BOM_Anomaly_OnlyList_withAnomalyWeights_Final.head())\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final.columns\n",
    "    \n",
    "    ### WRIING THE FIANL BOM ANOMALY LIST ONLY WITH CAUSES of ANOMALY IDENTIFED @@@@@@@@\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    BOM_Anomaly_OnlyList_withAnomalyWeights_Final.to_csv(\"BOM_Anomaly_OnlyList_withAnomalyWeights_Final_2\" + timestr + '.csv')\n",
    "    \n",
    "    end_ts= time.time()\n",
    "    total_ts =  end_ts - start_time\n",
    "    print(\"Total Duration of Code Execution is {}\".format(total_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7f2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h2o in c:\\users\\salsa\\anaconda3\\lib\\site-packages (3.40.0.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from h2o) (0.8.10)\n",
      "Requirement already satisfied: future in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from h2o) (0.18.2)\n",
      "Requirement already satisfied: requests in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from h2o) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from requests->h2o) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from requests->h2o) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from requests->h2o) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from requests->h2o) (2022.9.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salsa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "option --use-feature: invalid choice: '2020' (choose from '2020-resolver', 'fast-deps', 'truststore')\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\salsa\\\\anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "     -------------------------------------- 235.6/235.6 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------- 302.0/302.0 kB 19.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salsa\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     --------------------------------------- 14.9/14.9 MB 21.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, joblib, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "  Rolling back uninstall of numpy\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy-1.25.2.dist-info\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\~umpy-1.25.2.dist-info\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-7j4dgf2o\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__config__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__config__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__init__.cython-30.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__init__.cython-30.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__init__.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__init__.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\__config__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\__config__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\_distributor_init.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\_distributor_init.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\_globals.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\_globals.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\_pytesttester.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\_pytesttester.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\_version.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\_version.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\conftest.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\conftest.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\ctypeslib.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\ctypeslib.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\dtypes.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\dtypes.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\exceptions.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\exceptions.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\matlib.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\matlib.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\setup.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\setup.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\__pycache__\\version.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\__pycache__\\version.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_distributor_init.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_globals.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_globals.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_pyinstaller\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~-yinstaller\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_pytesttester.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_pytesttester.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_pytesttester.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_pytesttester.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_add_docstring.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_add_docstring.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_array_like.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_array_like.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_char_codes.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_char_codes.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_dtype_like.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_dtype_like.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_extended_precision.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_extended_precision.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_nbit.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_nbit.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_nested_sequence.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_nested_sequence.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_scalars.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_scalars.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\_shape.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\_shape.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\__pycache__\\setup.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\__pycache__\\setup.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_add_docstring.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_add_docstring.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_array_like.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_array_like.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_callable.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_callable.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_char_codes.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_char_codes.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_dtype_like.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_dtype_like.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_extended_precision.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_extended_precision.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_nbit.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_nbit.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_nested_sequence.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_nested_sequence.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_scalars.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_scalars.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_shape.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_shape.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\_ufunc.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\_ufunc.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_typing\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_typing\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_utils\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~utils\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\_version.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\_version.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\array_api\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~-ray_api\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\__pycache__\\py3k.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\__pycache__\\py3k.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\__pycache__\\setup.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\__pycache__\\setup.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\py3k.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\py3k.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\compat\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\compat\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\compat\\~ests\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\conftest.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\conftest.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\core\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_add_newdocs.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_add_newdocs.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_add_newdocs_scalars.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_add_newdocs_scalars.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_asarray.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_asarray.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_dtype.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_dtype.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_dtype_ctypes.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_dtype_ctypes.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_exceptions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_exceptions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_internal.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_internal.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_internal.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_internal.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_machar.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_machar.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_methods.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_multiarray_tests.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_multiarray_tests.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_multiarray_umath.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_multiarray_umath.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_operand_flag_tests.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_operand_flag_tests.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_rational_tests.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_rational_tests.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_simd.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_simd.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_string_helpers.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_string_helpers.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_struct_ufunc_tests.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_struct_ufunc_tests.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_type_aliases.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_type_aliases.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_type_aliases.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_type_aliases.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_ufunc_config.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_ufunc_config.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_ufunc_config.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_ufunc_config.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\_umath_tests.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\_umath_tests.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\arrayprint.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\arrayprint.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\arrayprint.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\cversions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\cversions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\defchararray.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\defchararray.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\defchararray.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\defchararray.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\einsumfunc.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\einsumfunc.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\fromnumeric.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\fromnumeric.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\function_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\function_base.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\function_base.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\generate_numpy_api.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\generate_numpy_api.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\getlimits.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\getlimits.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\getlimits.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\getlimits.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\.doxyfile\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\.doxyfile\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\__multiarray_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\__multiarray_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\__ufunc_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\__ufunc_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\_dtype_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\_dtype_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\_neighborhood_iterator_imp.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\_neighborhood_iterator_imp.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\_numpyconfig.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\_numpyconfig.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\_numpyconfig.h.in\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\_numpyconfig.h.in\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\arrayobject.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\arrayscalars.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\experimental_dtype_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\experimental_dtype_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\halffloat.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\halffloat.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\libdivide\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\core\\include\\numpy\\~ibdivide\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\ndarrayobject.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\ndarraytypes.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\noprefix.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\noprefix.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_1_7_deprecated_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_3kcompat.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_3kcompat.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_common.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_common.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_cpu.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_cpu.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_endian.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_endian.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_interrupt.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_interrupt.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_math.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_math.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_no_deprecated_api.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_no_deprecated_api.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_os.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\npy_os.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\numpyconfig.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\numpyconfig.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\old_defines.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\old_defines.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\oldnumeric.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\oldnumeric.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\random\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\core\\include\\numpy\\~andom\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\ufuncobject.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\include\\numpy\\utils.h\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\include\\numpy\\utils.h\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\lib\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\core\\~-b\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\memmap.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\memmap.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\memmap.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\multiarray.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\multiarray.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\multiarray.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\multiarray.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\numeric.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\numeric.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\numerictypes.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\numerictypes.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\numerictypes.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\numerictypes.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\overrides.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\records.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\records.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\records.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\records.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\setup_common.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\setup_common.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\shape_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\shape_base.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\core\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\umath.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\umath.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\core\\umath_tests.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\core\\umath_tests.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ctypeslib.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ctypeslib.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ctypeslib.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ctypeslib.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\__config__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\__config__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\_shell_utils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\_shell_utils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\armccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\armccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\ccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\ccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\ccompiler_opt.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\ccompiler_opt.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\checks\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~-ecks\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\command\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~-mmand\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\conv_template.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\conv_template.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\core.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\core.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\cpuinfo.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\cpuinfo.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\exec_command.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\exec_command.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\extension.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\extension.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\fcompiler\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~-ompiler\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\from_template.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\from_template.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\fujitsuccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\fujitsuccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\intelccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\intelccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\lib2def.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\lib2def.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\line_endings.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\line_endings.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\log.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\log.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\mingw32ccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\mingw32ccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\mingw\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~-ngw\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\misc_util.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\misc_util.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\msvc9compiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\msvc9compiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\msvccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\msvccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\npy_pkg_config.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\npy_pkg_config.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\numpy_distribution.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\numpy_distribution.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\pathccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\pathccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\system_info.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\system_info.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\distutils\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\distutils\\unixccompiler.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\distutils\\unixccompiler.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\doc\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~oc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\dtypes.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\dtypes.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\dtypes.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\dtypes.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\exceptions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\exceptions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\exceptions.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\exceptions.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\__main__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\__main__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\f2py\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\__version__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\__version__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\auxfuncs.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\auxfuncs.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\capi_maps.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\capi_maps.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\cb_rules.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\cb_rules.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\cfuncs.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\cfuncs.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\common_rules.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\common_rules.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\crackfortran.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\crackfortran.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\diagnose.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\diagnose.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\f2py2e.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\f2py2e.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\f90mod_rules.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\f90mod_rules.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\func2subr.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\func2subr.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\rules.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\rules.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\src\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\f2py\\~-c\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\symbolic.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\symbolic.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\f2py\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\f2py\\use_rules.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\f2py\\use_rules.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\fft\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~ft\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\lib\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\_datasource.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\_iotools.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\_iotools.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\_version.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\_version.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\_version.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\_version.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraypad.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arraypad.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraypad.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arraypad.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arraysetops.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arraysetops.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arrayterator.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arrayterator.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\arrayterator.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\arrayterator.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\format.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\format.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\function_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\function_base.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\histograms.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\histograms.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\index_tricks.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\index_tricks.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\mixins.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\mixins.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\mixins.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\mixins.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\nanfunctions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\nanfunctions.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\npyio.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\npyio.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\polynomial.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\polynomial.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\recfunctions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\recfunctions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\scimath.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\scimath.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\scimath.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\scimath.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\shape_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\shape_base.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\stride_tricks.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\stride_tricks.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\lib\\tests\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\data\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\lib\\tests\\~-ta\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test__datasource.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test__datasource.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test__iotools.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test__iotools.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test__version.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test__version.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_arraypad.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_arraypad.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_arraysetops.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_arraysetops.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_arrayterator.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_arrayterator.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_financial_expired.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_financial_expired.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_format.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_format.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_function_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_function_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_histograms.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_histograms.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_index_tricks.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_index_tricks.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_io.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_io.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_loadtxt.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_loadtxt.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_mixins.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_mixins.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_nanfunctions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_nanfunctions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_packbits.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_packbits.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_polynomial.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_polynomial.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_recfunctions.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_recfunctions.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_regression.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_regression.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_shape_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_shape_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_stride_tricks.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_stride_tricks.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_twodim_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_twodim_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_type_check.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_type_check.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_ufunclike.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_ufunclike.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\tests\\test_utils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\tests\\test_utils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\twodim_base.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\twodim_base.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\twodim_base.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\type_check.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\type_check.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\type_check.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\type_check.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\ufunclike.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\ufunclike.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\ufunclike.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\ufunclike.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\user_array.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\user_array.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\utils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\utils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\lib\\utils.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\lib\\utils.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\license.txt\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\license.txt\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\linalg\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~inalg\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\core.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\core.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\extras.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\extras.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\mrecords.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\mrecords.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\setup.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\setup.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\testutils.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\testutils.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\__pycache__\\timer_comparison.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\__pycache__\\timer_comparison.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\core.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\core.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\core.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\extras.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\extras.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\extras.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\mrecords.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\mrecords.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\mrecords.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\mrecords.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\ma\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\testutils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\testutils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\ma\\timer_comparison.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\ma\\timer_comparison.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\matlib.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\matlib.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\matrixlib\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~-trixlib\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\polynomial\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~-lynomial\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\py.typed\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\py.typed\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\__init__.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\__init__.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_bounded_integers.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_bounded_integers.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_bounded_integers.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_bounded_integers.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_common.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_common.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_common.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_common.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_examples\\cffi\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\_examples\\~-fi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_examples\\cython\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\_examples\\~-thon\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_examples\\numba\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\_examples\\~-mba\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_generator.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_generator.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_generator.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_generator.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_mt19937.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_mt19937.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_mt19937.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_mt19937.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_pcg64.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_pcg64.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_pcg64.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_pcg64.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_philox.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_philox.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_philox.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_philox.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_pickle.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_pickle.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_sfc64.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_sfc64.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\_sfc64.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\_sfc64.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\bit_generator.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\bit_generator.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\bit_generator.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\bit_generator.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\bit_generator.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\bit_generator.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\c_distributions.pxd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\c_distributions.pxd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\lib\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\~-b\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\mtrand.cp39-win_amd64.pyd\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\mtrand.cp39-win_amd64.pyd\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\mtrand.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\mtrand.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\random\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\random\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\random\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__init__.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__init__.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__pycache__\\overrides.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__pycache__\\overrides.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__pycache__\\print_coercion_tables.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__pycache__\\print_coercion_tables.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\__pycache__\\setup.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\__pycache__\\setup.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\__pycache__\\extbuild.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\__pycache__\\extbuild.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\__pycache__\\utils.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\__pycache__\\utils.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\extbuild.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\extbuild.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\utils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\utils.pyi\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\_private\\utils.pyi\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\overrides.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\overrides.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\print_coercion_tables.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\print_coercion_tables.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\tests\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\tests\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\tests\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\tests\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\tests\\__pycache__\\test_utils.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\tests\\__pycache__\\test_utils.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\testing\\tests\\test_utils.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\testing\\tests\\test_utils.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\tests\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\~-sts\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\__pycache__\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\typing\\~_pycache__\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\mypy_plugin.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\mypy_plugin.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\setup.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\setup.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\__init__.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\__init__.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\__pycache__\\__init__.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\__pycache__\\__init__.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\__pycache__\\test_isfile.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\__pycache__\\test_isfile.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\__pycache__\\test_runtime.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\__pycache__\\test_runtime.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\__pycache__\\test_typing.cpython-39.pyc\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\__pycache__\\test_typing.cpython-39.pyc\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\data\\\n",
      "   from C:\\Users\\salsa\\anaconda3\\Lib\\site-packages\\numpy\\typing\\tests\\~ata\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\test_isfile.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\test_isfile.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\test_runtime.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\test_runtime.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\typing\\tests\\test_typing.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\typing\\tests\\test_typing.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\lib\\site-packages\\numpy\\version.py\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-qpbxs4fv\\version.py\n",
      "  Moving to c:\\users\\salsa\\anaconda3\\scripts\\f2py.exe\n",
      "   from C:\\Users\\salsa\\AppData\\Local\\Temp\\pip-uninstall-4wkkpkep\\f2py.exe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salsa\\Documents\\BOM_Anomaly_autoencoder_CONCAT_CODE\n",
      "C:\\Users\\salsa\\Documents\\BOM_Anomaly_autoencoder_CONCAT_CODE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "#!conda install numpy --force-reinstall\n",
    "np.__version__\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "#pd.set_option('max_columns', None)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install h2o\n",
    "import seaborn as sns\n",
    "#import h2o\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler,Normalizer\n",
    "#from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize']=15,10\n",
    "\n",
    "import time\n",
    "!pip install sklearn --use-feature=2020\n",
    "start = time.time()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10, floor\n",
    "from sklearn import metrics\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "###############Random Bagging Ensemble- using- Bagging - random sample with replacement, \n",
    "## Random sampling using features subsets-Random Sub-Space, & Random sampling- combine both Features \n",
    "### & Sample -Random batches ####\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "########### Importing sklearn Stats\n",
    "import scipy.stats as stats\n",
    "#import loguniform\n",
    "\n",
    "############GBM \n",
    "#import lightgbm as lgb\n",
    "###############\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "####### Cell multiple Display  ##\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "####### GridSearch and Skllearn Libraries\n",
    "\n",
    "#Data Mining\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#import model_selection \n",
    "import statsmodels\n",
    "\n",
    "#Classifier scoring\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "\n",
    "## turning off depracation messages\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "## working directory\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# ####### Class Imbalance SMOTE ######\n",
    "!pip install imblearn\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from StringIO import StringIO\n",
    "import gzip\n",
    "#from urllib import urlopen\n",
    "\n",
    "import requests\n",
    "#from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "##os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\sipp')\n",
    "#os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "##  Code Execution time\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "import numpy as np; np.random.seed(136)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pylab\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['lines.color'] = 'r'\n",
    "from numpy import argmax\n",
    "########## Importing sklearn Stats\n",
    "import scipy.stats as stats\n",
    "# import loguniform\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# ### Warning messages mode  ####\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "####### Cell multiple Display Config ##\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## turning off depracation messages\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "path1=os.getcwd()\n",
    "#os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "print(os.getcwd())\n",
    "\n",
    "############# Printing Plot output ###############\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "pd.options.display.max_rows = 4000\n",
    "############################# Decision Tree Plots & Viz Libs  #####################\n",
    "import scipy\n",
    "from sys import getsizeof\n",
    "from IPython.display import Image\n",
    "from matplotlib import pylab\n",
    "from sklearn.tree import _tree\n",
    "#from skrules import SkopeRules\n",
    "###### Accuracy Paramters\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "import unittest\n",
    "## range to xrange copatability in python 2 &#3\n",
    "try:\n",
    "    # Python 2 forward compatibility\n",
    "    range = xrange\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "#####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "import future  , builtins , past, six      \n",
    "from six import reraise as raise_\n",
    "from future.utils import raise_\n",
    "\n",
    "###################### Model Pickling & JSON Support Loads #################\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "#############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "# from smart_open import open\n",
    "# from smart_open import s3_iter_bucket\n",
    "# from smart_open import open\n",
    "# from smart_open import s3_iter_bucket\n",
    "# import gensim\n",
    "import os\n",
    "import collections\n",
    "# import smart_open\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "###################### IMPORT MODEL JOBLIB @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "#from __future__ import print_function\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "import socket\n",
    "from collections import Counter\n",
    "\n",
    "!conda install -c conda-forge h2o-py openjdk -y\n",
    "\n",
    "#import boto3\n",
    "from   IPython                   import display\n",
    "import matplotlib.pyplot         as plt\n",
    "import numpy                     as np\n",
    "import pandas                    as pd\n",
    "# import sagemaker\n",
    "# from sagemaker.tensorflow import TensorFlow\n",
    "# from sagemaker.tensorflow.serving import Model, Predictor\n",
    "# from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
    "# from   sklearn.decomposition     import PCA\n",
    "# #!pip install pytest-astropy    ############# Prequisite for Tensorflow install\n",
    "!pip install tensorflow\n",
    "import tensorflow                as tf\n",
    "from   tensorflow                import keras\n",
    "from   tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend  as K\n",
    "import time\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy       import stats\n",
    "from statistics  import mean\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import sys\n",
    "\n",
    "############################### LOADING SCORING DATA @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "from os import chdir\n",
    "#chdir(r'C:\\Users\\esalosm\\Documents\\Python Scripts')\n",
    "\n",
    "#### ACCESS to HDFS\n",
    "import h5py\n",
    "\n",
    "#### Function tools\n",
    "import functools\n",
    "from functools import partial\n",
    "from patsy import dmatrices\n",
    "####### Plots and Viz; Decision Trees, Ensemble, GridSearch and Skllearn , metrics, Data Split Libraries ############\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.pylab as plt\n",
    "from math import log10, floor\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn import preprocessing, cross_validation, svm, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "################################## Esnemble Models #######################\n",
    "### Xgboost load\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from timeit import Timer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "################### MODEL Accuracy Metrics ################\n",
    "import sklearn\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#style.use('ggplot')\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pylab\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['lines.color'] = 'r'\n",
    "from numpy import argmax\n",
    "########## Importing sklearn Stats\n",
    "import scipy.stats as stats\n",
    "# import loguniform\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# ### Warning messages mode  ####\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "####### Cell multiple Display Config ##\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## turning off depracation messages\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#path1=os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts')\n",
    "path1=os.getcwd()\n",
    "#os.chdir(r'C:\\Users\\ESALOSM\\Documents\\Python_scripts\\COMBINED_COMMENTS')\n",
    "print(os.getcwd())\n",
    "\n",
    "############# Printing Plot output ###############\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "pd.options.display.max_rows = 4000\n",
    "############################# Decision Tree Plots & Viz Libs  #####################\n",
    "import scipy\n",
    "from sys import getsizeof\n",
    "from IPython.display import Image\n",
    "from matplotlib import pylab\n",
    "from sklearn.tree import _tree\n",
    "#from skrules import SkopeRules\n",
    "###### Accuracy Paramters\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, make_scorer, recall_score, classification_report,            confusion_matrix\n",
    "import unittest\n",
    "## range to xrange copatability in python 2 &#3\n",
    "# try:\n",
    "#     # Python 2 forward compatibility\n",
    "#     range = xrange\n",
    "# except NameError:\n",
    "#     pass\n",
    "\n",
    "#####  Learning to Rank using LambadaMart, LambadaRank, SVM Rank\n",
    "import future  , builtins , past, six      \n",
    "from six import reraise as raise_\n",
    "from future.utils import raise_\n",
    "\n",
    "###################### Model Pickling & JSON Support Loads #################\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "#############  OPEN SMART Form all File Systems Sources HDFS, S3, Local ,  web, ssh, aaaatc\"\"\"\"\"\"\"\"\"\"\n",
    "# from smart_open import open\n",
    "# from smart_open import s3_iter_bucket\n",
    "# from smart_open import open\n",
    "# from smart_open import s3_iter_bucket\n",
    "# import gensim\n",
    "import os\n",
    "import collections\n",
    "# import smart_open\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "# sys.setrecursionlimit(1500)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    ####################################### BOM Data Ingestion Section  ##############################\n",
    "    #Pathtot_TrainBOM= (r'C:\\Users\\salsa\\Documents\\Anomaly_Detction_AUTOENCODER_MODEL_Master\\train\\atAall_csv.csv')\n",
    "    Pathtot_TrainBOM= (r'/home/saosman/anomaly_Detection_Autoencoder_Model_H2O/train')\n",
    "    \n",
    "    #/anomaly_Detection_Autoencoder_Model_H2O\n",
    "    #Path_1= (r'C:\\Users\\esalosm\\Documents\\Python Scripts\\TELFONIOCA_ESR_BOM\\TELECOM ITALIA_PROD_AggregatedBom.csv')\n",
    "    Path_toFASID =(r'/home/saosman/anomaly_Detection_Autoencoder_Model_H2O/fas')\n",
    "    #Path_toFASID =(r'C:\\Users\\salsa\\Documents/Anomaly_Detction_AUTOENCODER_MODEL_Master\\fas\\site_inf_csv.csv')\n",
    "    \n",
    "    #/anomaly_Detection_Autoencoder_Model_H2O\n",
    "    Path_toBOM_Anom_Scoring= (r'/home/saosman/anomaly_Detection_Autoencoder_Model_H2O/test')\n",
    "    #Path_toBOM_Anom_Scoring= (r'C:\\Users\\salsa\\Documents\\Anomaly_Detction_AUTOENCODER_MODEL_Master\\test\\test_set_final_csv.csv')\n",
    "    \n",
    "    #/anomaly_Detection_Autoencoder_Model_H2O\n",
    "#     Path_3=(r'C:\\Users\\esalosm\\Documents\\Python Scripts\\ATT_ESR_BOM\\AT&T_PROD_ExportAggregatedBom.csv')\n",
    "#     Path_4=(r'C:\\Users\\esalosm\\Documents\\Python Scripts\\ATT_ESR_BOM\\ESR_ BOM Change Requests Approved_CSV.csv')\n",
    "#     Path_5=(r'C:\\Users\\esalosm\\Documents\\Python Scripts\\BOM_Anomaly_Detection\\dataaboutsiteFAS_csv.csv')\n",
    "    all_ops_bom_train_val_df, all_FASfiles_df, all_ops_bom_anomalyScore_file_df = Site_BOM_data_ingestion(Pathtot_TrainBOM, Path_toFASID, Path_toBOM_Anom_Scoring)\n",
    "    #Pathtot_TrainBOM, Path_toFASID, Path_toBOM_Anom_Scoring\n",
    "    ###################################### Data Pre-Processing Section ###############################\n",
    "\n",
    "    SiteBOM_Data_Train_preprocess_pipe(all_ops_bom_train_val_df, all_FASfiles_df , all_ops_bom_anomalyScore_file_df)\n",
    "    ## all_ops_bom_FAS_df,\n",
    "    ##################### Model FIT Section  @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "        \n",
    "    Site_BOM_train_fit(ESR_approved_bom_11_4 , ESR_approved_bom_22_4, all_ops_bom_anomalyScore_file_df_4_5)\n",
    "#     from h2o.estimators.deeplearning import H2OAutoEncoderEstimator\n",
    "#     model= H2OAutoEncoderEstimator(activation=\"Tanh\",\n",
    "#                               hidden=[120],\n",
    "#                               ignore_const_cols=False,\n",
    "#                               epochs=100)\n",
    "    #model= bestModel\n",
    "    ############################# Model Inference Anomaly Prediction @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    \n",
    "    node_fault_scoring(ESR_approved_bom_11_4_hex, ESR_approved_bom_22_4_hex, all_ops_bom_anomalyScore_file_df_4_5_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fe67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy --upgrade --user\n",
    "#!conda install numpy --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa62432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a81610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ip = get_ipython()\n",
    "ip.InteractiveTB.set_mode(mode=\"Verbose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8fdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
